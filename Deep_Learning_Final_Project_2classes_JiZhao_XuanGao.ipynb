{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Final_Project_2classes_JiZhao_XuanGao.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HFFiW_zFr8Y",
        "colab_type": "text"
      },
      "source": [
        "#### Reference code\n",
        "1. https://github.com/cbaziotis/ekphrasis\n",
        "2. https://github.com/google-research/bert/blob/master/run_classifier.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGvdwnTtGRG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/5922NeuralNetworkAndDeepLearning/FinalProject"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghOWOH40HMN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install emoji --upgrade  # install emoji package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-49kXRG58Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install ekphrasis        # install package to process emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYNtxqZ8G6HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import emoji\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz0JPYvcHn01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUv1bf8xHqHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CICa9pBIIA7U",
        "colab_type": "text"
      },
      "source": [
        "###Loading The Data & processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cAXoP7xIG09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ei_oc_train_file = ['2-EI-oc-En-train/EI-oc-En-anger-train.txt']#,'2-EI-oc-En-train/EI-oc-En-fear-train.txt','2-EI-oc-En-train/EI-oc-En-joy-train.txt','2-EI-oc-En-train/EI-oc-En-sadness-train.txt']\n",
        "ei_oc_dev_file = ['2-EI-oc-En-dev/EI-oc-En-anger-dev.txt']#,'2-EI-oc-En-dev/EI-oc-En-fear-dev.txt','2-EI-oc-En-dev/EI-oc-En-joy-dev.txt','2-EI-oc-En-dev/EI-oc-En-sadness-dev.txt']\n",
        "ei_oc_test_file = ['2-EI-oc-En-test/EI-oc-En-anger-test.txt']#,'2-EI-oc-En-test/EI-oc-En-fear-test.txt','2-EI-oc-En-test/EI-oc-En-joy-test.txt','2-EI-oc-En-test/EI-oc-En-sadness-test.txt']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxM12SEUIXyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class read_file():\n",
        "  def __init__(self, train_file, dev_file, test_file):\n",
        "    self.train_file = train_file\n",
        "    self.dev_file = dev_file\n",
        "    self.test_file = test_file\n",
        "\n",
        "  def read_data(self):\n",
        "    train_data =  pd.read_csv(self.train_file, sep = '\\t')\n",
        "    dev_data =  pd.read_csv(self.dev_file, sep = '\\t')\n",
        "    test_data =  pd.read_csv(self.test_file, sep = '\\t')\n",
        "    return train_data, dev_data, test_data\n",
        "\n",
        "  def array_format_data(self):\n",
        "    train_data, dev_data, test_data = self.read_data()\n",
        "    train_title = train_data.columns[:-1]\n",
        "    target_title = train_data.columns[-1]\n",
        "\n",
        "    train_data_array = train_data[train_title].values\n",
        "    dev_data_array = dev_data[train_title].values\n",
        "    test_data_array = test_data[train_title].values\n",
        "\n",
        "    train_target_array = train_data[target_title].values\n",
        "    dev_target_array = dev_data[target_title].values\n",
        "    return train_data_array, dev_data_array, test_data_array, train_target_array, dev_target_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R078_fInIb7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ei_oc_files = [ei_oc_train_file, ei_oc_dev_file, ei_oc_test_file]\n",
        "train_data_array, dev_data_array, test_data_array, train_target_array, dev_target_array = dict(), dict(), dict(), dict(), dict()\n",
        "train_data, dev_data, test_data, train_target_array_first_col, dev_target_array_first_col = dict(), dict(), dict(), dict(), dict()\n",
        "\n",
        "files = [ei_oc_files] \n",
        "\n",
        "files_len = len(files)\n",
        "for i in range(len(files)):\n",
        "  read_file_obj = read_file(files[i][0][0], files[i][1][0], files[i][2][0])\n",
        "  train_data[i], dev_data[i], test_data[i] = read_file_obj.read_data()\n",
        "  train_data_array[i], dev_data_array[i], test_data_array[i], train_target_array[i], dev_target_array[i] = read_file_obj.array_format_data()\n",
        "  train_target_num = []\n",
        "  dev_target_num = []\n",
        "  for d in train_target_array[i]:\n",
        "    train_target_num.append(int(d.split(\":\")[0]))\n",
        "  for d in dev_target_array[i]:\n",
        "    dev_target_num.append(int(d.split(\":\")[0]))\n",
        "  train_target_array_first_col[i] = train_target_num\n",
        "  dev_target_array_first_col[i] = dev_target_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okpeVyu-I_ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class process_data():\n",
        "  def __init__(self, train_data_array, dev_data_array, test_data_array):\n",
        "    self.train_data_array = train_data_array\n",
        "    self.dev_data_array = dev_data_array\n",
        "    self.test_data_array = test_data_array\n",
        "\n",
        "  def preprocessing_text(self, file_name):\n",
        "    from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "    from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "    from ekphrasis.dicts.emoticons import emoticons\n",
        "\n",
        "    text_processor = TextPreProcessor(\n",
        "        # terms that will be normalized\n",
        "        normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "            'time', 'url', 'date', 'number'],\n",
        "        # terms that will be annotated\n",
        "        annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "            'emphasis', 'censored'},\n",
        "        fix_html=True,  # fix HTML tokens\n",
        "\n",
        "        # corpus from which the word statistics are going to be used \n",
        "        # for word segmentation \n",
        "        segmenter=\"twitter\", \n",
        "\n",
        "        # corpus from which the word statistics are going to be used \n",
        "        # for spell correction\n",
        "        corrector=\"twitter\", \n",
        "\n",
        "        unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "        unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "        spell_correct_elong=False,  # spell correction for elongated words\n",
        "\n",
        "        # select a tokenizer. \n",
        "        tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "\n",
        "        # list of dictionaries, for replacing tokens extracted from the text,\n",
        "        # with other expressions. You can pass more than one dictionaries.\n",
        "        dicts=[emoticons]\n",
        "    )\n",
        "    sentences = []\n",
        "    for i in file_name:\n",
        "        temp = [i]\n",
        "        sentences.append(temp)\n",
        "    result = []\n",
        "    for s in sentences:\n",
        "        temp = emoji.demojize(s[0])\n",
        "        result.append(\" \".join(text_processor.pre_process_doc(temp)))\n",
        "    return np.array(result)\n",
        "\n",
        "  def transfor_tweet_data(self):\n",
        "    preprocessed_tweet_train = dict()\n",
        "    preprocessed_tweet_dev = dict()\n",
        "    preprocessed_tweet_test = dict()\n",
        "    for i in range(files_len):\n",
        "      preprocessed_tweet_train[i] = self.preprocessing_text(self.train_data_array[i][:,1])\n",
        "      preprocessed_tweet_dev[i] = self.preprocessing_text(self.dev_data_array[i][:,1])\n",
        "      preprocessed_tweet_test[i] = self.preprocessing_text(self.test_data_array[i][:,1])\n",
        "    return preprocessed_tweet_train, preprocessed_tweet_dev, preprocessed_tweet_test\n",
        "    \n",
        "  def transfor_array_to_dataFrame(self):\n",
        "    train_X = dict()\n",
        "    dev_X = dict()\n",
        "    test_X = dict()\n",
        "\n",
        "    train_y = dict()\n",
        "    dev_y = dict()\n",
        "    preprocessed_tweet_train, preprocessed_tweet_dev, preprocessed_tweet_test = self.transfor_tweet_data()\n",
        "    for i in range(files_len):\n",
        "      train_X[i] = pd.DataFrame.from_dict(preprocessed_tweet_train[i])\n",
        "      dev_X[i] = pd.DataFrame.from_dict(preprocessed_tweet_dev[i])\n",
        "      test_X[i] = pd.DataFrame.from_dict(preprocessed_tweet_test[i])\n",
        "      \n",
        "      train_X[i].columns=['Tweet']\n",
        "      dev_X[i].columns=['Tweet']\n",
        "      test_X[i].columns=['Tweet']\n",
        "\n",
        "      train_y[i] = pd.DataFrame.from_dict(train_target_array_first_col[i])\n",
        "      dev_y[i] = pd.DataFrame.from_dict(dev_target_array_first_col[i])\n",
        "      \n",
        "      train_y[i].columns=['Score']\n",
        "      dev_y[i].columns=['Score']\n",
        "\n",
        "    return train_X, dev_X, test_X, train_y, dev_y\n",
        "\n",
        "  def combine_dataFrame_Xy(self):\n",
        "    bert_train_Xy = dict()\n",
        "    bert_dev_Xy = dict()\n",
        "    train_X, dev_X, test_X, train_y, dev_y = self.transfor_array_to_dataFrame()\n",
        "    for i in range(len(train_X)):\n",
        "      bert_train_Xy[i] = pd.concat([train_X[i],train_y[i]], axis=1)\n",
        "      bert_dev_Xy[i] = pd.concat([dev_X[i], dev_y[i]], axis=1)\n",
        "    return bert_train_Xy, bert_dev_Xy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1IJVAcLJLnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process_data_obj = process_data(train_data_array, dev_data_array, test_data_array)\n",
        "bert_train_Xy, bert_dev_Xy = process_data_obj.combine_dataFrame_Xy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbaCupZPNrv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transclass(dframe):\n",
        "  for i in range(len(dframe)):\n",
        "    if dframe.loc[i,'Score'] >1:\n",
        "      dframe.loc[i,'Score'] =1\n",
        "    else:\n",
        "      dframe.loc[i,'Score'] =0\n",
        "  return dframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqjRzwRHLuW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_train_Xy[0] = transclass(bert_train_Xy[0])\n",
        "bert_dev_Xy[0] = transclass(bert_dev_Xy[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwvIUjGKNXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'Tweet'\n",
        "LABEL_COLUMN = 'Score'\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [[0,1],[0,1,2,3],np.arange(-3,3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZvh2qRPjdA",
        "colab_type": "text"
      },
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zKaBhoPlmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_examples(data, DATA_COLUMN, LABEL_COLUMN):\n",
        "  InputExamples = data.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "  return InputExamples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXDbwQHpQGDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_examples_result(bert_train_Xy, bert_dev_Xy, DATA_COLUMN, LABEL_COLUMN):\n",
        "  train_InputExamples = dict()\n",
        "  dev_InputExamples = dict()\n",
        "  for i in range(files_len):\n",
        "    train_InputExamples[i] = input_examples(bert_train_Xy[i], DATA_COLUMN, LABEL_COLUMN)  \n",
        "    dev_InputExamples[i] = input_examples(bert_dev_Xy[i], DATA_COLUMN, LABEL_COLUMN)\n",
        "  return train_InputExamples, dev_InputExamples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4YzJvBP8my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvjVmeqdQqrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples, dev_InputExamples = input_examples_result(bert_train_Xy, bert_dev_Xy, DATA_COLUMN, LABEL_COLUMN)\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaRuQ4E3Qz4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples[0].iloc[2].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples[0].iloc[2].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples[0].iloc[2].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples[0].iloc[2].label)\n",
        "print(tokenizer.tokenize(train_InputExamples[0].iloc[2].text_a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBlmrzi-RGPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = dict()\n",
        "dev_features = dict()\n",
        "MAX_SEQ_LENGTH_List = [64]#,8,32]\n",
        "\n",
        "for i in range(len(MAX_SEQ_LENGTH_List)):\n",
        "  train_features[MAX_SEQ_LENGTH_List[i]] = bert.run_classifier.convert_examples_to_features(train_InputExamples[0], label_list[0], MAX_SEQ_LENGTH_List[i], tokenizer)\n",
        "  dev_features[MAX_SEQ_LENGTH_List[i]] = bert.run_classifier.convert_examples_to_features(dev_InputExamples[0], label_list[0], MAX_SEQ_LENGTH_List[i], tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgLazSKBRkuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Sentence : \", train_InputExamples[0].iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples[0].iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[64][0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[64][0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[64][0].segment_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USNencbtR-bQ",
        "colab_type": "text"
      },
      "source": [
        "### creating a multiple-class classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0HCi1WzRwyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use some function from https://github.com/google-research/bert/run_classfier.py\n",
        "\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        " \n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9-BfgQSIrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tAN-OuStvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE_List = [8,50,100]\n",
        "LEARNING_RATE_List = [1e-5]#, 2e-5, 5e-5]\n",
        "NUM_TRAIN_EPOCHS_List = [5]#,10]\n",
        "\n",
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = dict()\n",
        "num_warmup_steps = dict()\n",
        "for BATCH_SIZE in BATCH_SIZE_List:\n",
        "  for NUM_TRAIN_EPOCHS in NUM_TRAIN_EPOCHS_List:\n",
        "    num_train_steps[BATCH_SIZE,NUM_TRAIN_EPOCHS] = int(len(train_features[MAX_SEQ_LENGTH_List[0]]) /  BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps[BATCH_SIZE,NUM_TRAIN_EPOCHS] = int(num_train_steps[BATCH_SIZE,NUM_TRAIN_EPOCHS] * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B440zblS7cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(num_train_steps.values())\n",
        "for k,v in num_train_steps.items():\n",
        "  print(k,num_train_steps[k])\n",
        "  print('warm up',num_warmup_steps[k])\n",
        "# num_train_steps.values()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV6IUJ6iS-LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O1Envv7TV_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = dict()\n",
        "estimator = dict()\n",
        "train_input_fn = dict()\n",
        "dev_input_fn = dict()\n",
        "evaluate_result=dict()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfd5Jp2o8Fsy",
        "colab_type": "text"
      },
      "source": [
        "###train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4O6pJPZTagC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1):#(len(LEARNING_RATE_List)):\n",
        "  # 1e-5,2e-5,5e-5\n",
        "  for k,v in num_train_steps.items():\n",
        "    # (8,5),(8,10),(50,5),(50,10),(100,5),(100,10)\n",
        "    model_fn[i,k] = model_fn_builder(\n",
        "        num_labels=len(label_list[0]),\n",
        "        learning_rate=LEARNING_RATE_List[i],\n",
        "        num_train_steps=num_train_steps[k],\n",
        "        num_warmup_steps=num_warmup_steps[k])\n",
        "    # since the limitation of disk and ram, we choose toe run 2 max_seq_length every time.\n",
        "    for MAX_SEQ_LENGTH in MAX_SEQ_LENGTH_List[:1]:\n",
        "      # 64，8，32, 128.\n",
        "      estimator[i, MAX_SEQ_LENGTH, k] = tf.estimator.Estimator(\n",
        "          model_fn=model_fn[i,k],\n",
        "          config=run_config,\n",
        "          params={\"batch_size\": k[0]})\n",
        "      train_input_fn[MAX_SEQ_LENGTH] = bert.run_classifier.input_fn_builder(\n",
        "          features=train_features[MAX_SEQ_LENGTH],\n",
        "          seq_length=MAX_SEQ_LENGTH,\n",
        "          is_training=True,\n",
        "          drop_remainder=False)\n",
        "      print(f'Beginning Training!')\n",
        "      current_time = datetime.now()\n",
        "      estimator[i,MAX_SEQ_LENGTH, k].train(input_fn=train_input_fn[MAX_SEQ_LENGTH], max_steps=num_train_steps[k])\n",
        "      print(\"Training took time \", datetime.now() - current_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t6ldGK0kOVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(estimator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU5t7TZuVs4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1):#(len(LEARNING_RATE_List)):\n",
        "  for k,v in num_train_steps.items():\n",
        "    for MAX_SEQ_LENGTH in MAX_SEQ_LENGTH_List[:1]:\n",
        "      dev_input_fn[MAX_SEQ_LENGTH] = run_classifier.input_fn_builder(\n",
        "          features=dev_features[MAX_SEQ_LENGTH],\n",
        "          seq_length=MAX_SEQ_LENGTH,\n",
        "          is_training=False,\n",
        "          drop_remainder=False)\n",
        "      evaluate_result[i,MAX_SEQ_LENGTH, k]=estimator[i,MAX_SEQ_LENGTH, k].evaluate(input_fn=dev_input_fn[MAX_SEQ_LENGTH], steps=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH9gGxvDf883",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k,v in evaluate_result.items():\n",
        "  print(k,v)   # The result of evaulate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er80hwRcI-pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}